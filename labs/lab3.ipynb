{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dd1ff0",
   "metadata": {},
   "source": [
    "# Computer Exercise 3: Recursive Estimation and Models with Time-Varying Parameters\n",
    "\n",
    "Time Series Analysis  \n",
    "Lund University  \n",
    "2025\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This computer exercise treats recursive parameter estimation using Kalman filtering and recursive least squares. We attempt to model dynamic systems of both the SARIMA-type, having time-varying A and C polynomials, as well as to allow for ARMAX processes which have a synthetic input signal and time-varying B polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b49723c",
   "metadata": {},
   "source": [
    "## Preparations before the lab\n",
    "\n",
    "Read Chapter 8 in the course textbook as well as this guide to the computer exercise.\n",
    "\n",
    "Answers to some of the computer exercise will be graded using the course's *Mozquizto* page, available at `https://quizms.maths.lth.se`. Ensure that you can access the system before the exercise and answer the preparatory questions as well as (at least) three of numbered exercise questions below *before the exercise*. These questions aim at allowing to check your implementation.\n",
    "\n",
    "Before the computer exercise:\n",
    "\n",
    "1. Express an AR(2) process on state space form and estimate the parameters of the process using a Kalman filter as specified in Sections 2.2 and 2.3.\n",
    "\n",
    "2. Write a Python script that simulates the process $u_t$ in Section 2.4 below. Let $u_t$ be a Markov chain that switches slowly between two states, using $p_{11}=p_{22}=7/8$ and $p_{12}=p_{21}=1/8$.  \n",
    "   Hint: This is easy to do using a loop where you at each time instance change state according to the specified probabilities.\n",
    "\n",
    "Note that you are expected to be able to answer detailed questions on your implementation.\n",
    "\n",
    "It should be stressed that a thorough understanding of the material in this exercise is important to be able to complete the course project, and we encourage you to discuss any questions you might have on the exercises with the teaching staff. This will save you a lot of time when you start working with the project!\n",
    "\n",
    "You are allowed to solve the exercise in groups of two, but not more. Please respect this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "# Import tsa_lth library\n",
    "import sys\n",
    "sys.path.append('../TimeSeriesAnalysis-main/TimeSeriesAnalysis-main')\n",
    "from tsa_lth.modelling import recursiveAR, recursiveARMA, filter, estimateARMA, PEM\n",
    "from tsa_lth.analysis import plotACFnPACF\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc273a2",
   "metadata": {},
   "source": [
    "## 2.1 Recursive least squares estimation\n",
    "\n",
    "Load the data material `tar2.dat`, the data is an AR(2)-process with one time dependent parameter and the other one constant. The correct parameter trajectories are stored in the file `thx.dat`. Use `subplot` to plot the data and the parameter in the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956cde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "tar2 = np.loadtxt('../data/tar2.dat')\n",
    "thx = np.loadtxt('../data/thx.dat')\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(1, figsize=(12, 6))\n",
    "plt.subplot(211)\n",
    "plt.plot(tar2)\n",
    "plt.title('tar2')\n",
    "plt.subplot(212)\n",
    "plt.plot(thx)\n",
    "plt.title('thx')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5736af",
   "metadata": {},
   "source": [
    "Use the Python `recursiveAR` to estimate the $A(z)$ polynomial recursively. Here, `Aest` is the estimated parameters, `yhat` is the estimate of $y_t$ based on the estimated $A(z)$ polynomial and past values of $y_t$. Try different forgetting factors, using ${\\lambda}= 1,\\, 0.95,\\, 0.9$. Plot the parameter estimates together with the true parameter. What effect does the value of $\\lambda$ have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc57feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different forgetting factors (lambdas)\n",
    "lambdas = [1, 0.95, 0.9]\n",
    "\n",
    "plt.figure(2, figsize=(12, 10))\n",
    "for i, lam in enumerate(lambdas):\n",
    "    # give it the data the model order, the forgetting factor and an initial guess for the parameters you can find the function in modeling.py\n",
    "    Aest, yhat = recursiveAR(?, ?, forgetting_factor=?, ?=np.array([[0], [0]]))\n",
    "    \n",
    "    # Plot a1 parameter\n",
    "    plt.subplot(3, 2, 2*i + 1)\n",
    "    plt.plot(Aest[:, 0], 'b', label='a1 estimate')\n",
    "    plt.plot(thx[:, 0], 'r', label='a1 true')\n",
    "    plt.title(f'Lambda = {lam}, a1')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot a2 parameter\n",
    "    plt.subplot(3, 2, 2*i + 2)\n",
    "    plt.plot(Aest[:, 1], 'b', label='a2 estimate')\n",
    "    plt.plot(thx[:, 1], 'r', label='a2 true')\n",
    "    plt.title(f'Lambda = {lam}, a2')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac4d26",
   "metadata": {},
   "source": [
    "To choose $\\lambda$, one option is to use the least squares estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal lambda\n",
    "n = 100\n",
    "lambda_line = np.linspace(0.85, 1, n)\n",
    "ls2 = np.zeros(n)\n",
    "\n",
    "for i in range(len(lambda_line)):\n",
    "    Aest, yhat = recursiveAR(tar2, order=2, forgetting_factor=lambda_line[i], theta_guess=np.array([[0], [0]]))\n",
    "    ls2[i] = np.sum((tar2 - yhat)**2)\n",
    "\n",
    "# Find minimum\n",
    "opt_ind = np.argmin(ls2)\n",
    "lambda_opt = lambda_line[opt_ind]\n",
    "\n",
    "print(f'Min LS: {ls2[opt_ind]:.4f} ; lambda:{lambda_opt:.4f}')\n",
    "\n",
    "# Plot\n",
    "plt.figure(3, figsize=(12, 6))\n",
    "plt.plot(lambda_line, ls2, 'b-')\n",
    "plt.plot(lambda_opt, ls2[opt_ind], 'r*', markersize=15)\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Sum of Squared Residuals')\n",
    "plt.title('Optimal Lambda Selection')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e85e2f",
   "metadata": {},
   "source": [
    "**Question 1**  \n",
    "In Mozquizto, answer question 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c45d2",
   "metadata": {},
   "source": [
    "## 2.2 Kalman filtering of time series\n",
    "\n",
    "A quite important drawback of the RLS estimate is that it should not be used to estimate MA parameters, making it unsuitable for, e.g., ARMA processes. We continue to again estimate the AR parameters from the previous section, but by using the Kalman filter. Note that the Kalman implementation can be extended to also allow for MA coefficients.\n",
    "\n",
    "We here make use of the example code given in Section 3. At first, ignore the part of the example code for the 2-step prediction. This code uses data up to time $t-1$ to predict the state value $\\hat{x}_{t|t-1}$, stored in the variable `x_t1`, and then use this value to predict (the one-step prediction) $\\hat{y}_{t|t-1}$. The prediction error (also often termed the prediction residual) between $\\hat{y}_{t|t-1}$ and $y_t$, i.e.,\n",
    "$$\n",
    "\\epsilon_{t|t} = y_t - \\hat{y}_{t|t-1}\n",
    "$$\n",
    "is then used to update the Kalman filter. Here, the prediction residual is stored in the variable `ehat`.\n",
    "\n",
    "Proceed to complete the missing part of the code (ignore the part for the 2-step prediction). Use the tar2 data as $y_t$. Then, to be able to check your implementation, set\n",
    "```python\n",
    "Re    = np.array([[0.004, 0], [0, 0]])\n",
    "Rw    = 1.25\n",
    "Rx_t1 = 10 * np.eye(2)\n",
    "```\n",
    "Also, set the initial value of the state vector to zero values. This will set the covariance matrix of the observation (`Re`) and measurement (`Rw`) noises, as well as the initial state vector and its covariance matrix. The large initial value for `Rx_t1`, i.e., $R^{x,x}_{t+1|t}$, indicates that we have little confidence in the initial states.\n",
    "\n",
    "Notice in particular that the way `Re` is selected reflects the assumption that the first parameter varies, whereas the second does not. Plot the resulting parameter estimates and notice the difference in convergence between the two parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b03516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code for task 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e91de",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "In Mozquizto, answer question 2.\n",
    "\n",
    "This question strives to check that your implementation is correct. As you will use this as the basis for the following steps, as well as in the project, it is important that you get this to work properly. Ask the teaching staff to help you if you do not get the correct answer!\n",
    "\n",
    "**Question 3**\n",
    "\n",
    "In Mozquizto, answer question 3.\n",
    "\n",
    "What effect has the choice of `Rw` and `Re` for the parameter estimates? Did you manage to improve the estimation by using Kalman filtering instead of RLS? Can you reduce the sum of the squared residual (`ehat`) by tuning `Re` and `Rw`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5762d1",
   "metadata": {},
   "source": [
    "## 2.3 Using the Kalman filter for prediction\n",
    "\n",
    "We now proceed to form a 2-step prediction using the Kalman filter. To do this, you need to complete the latter part of the example code. As it can be difficult to verify that the implementation is correct, we will use simulated data for this. To be able to check your implementation, use\n",
    "```python\n",
    "np.random.seed(0)\n",
    "N  = 10000\n",
    "ee = 0.1 * np.random.randn(N)\n",
    "A0 = np.array([1, -0.8, 0.2])\n",
    "y  = signal.lfilter([1], A0, ee)\n",
    "Re = np.array([[1e-6, 0], [0, 1e-6]])\n",
    "Rw = 0.1\n",
    "```\n",
    "We here select `Re` small to ensure that we get states that converge close to the true values (which is also why we select $N$ so large).\n",
    "\n",
    "In order to form $\\hat{y}_{t+2|t}$, you first need to form $\\hat{C}_{t+2|t}$, as\n",
    "$$\n",
    "\\hat{y}_{t+2|t} = \\hat{C}_{t+2|t} \\hat{x}_{t+2|t} = \\hat{C}_{t+2|t} \\hat{x}_{t|t}\n",
    "$$\n",
    "Note that, in general, $\\hat{x}_{t+2|t} \\neq \\hat{x}_{t|t}$. Why does this equality hold here?\n",
    "\n",
    "Proceed to write down an expression for $\\hat{C}_{t+2|t}$ and note that this will depend on $\\hat{y}_{t+1|t}$. As a result, you will first need to estimate $\\hat{y}_{t+1|t}$, then use this value to form $\\hat{C}_{t+2|t}$, and then finally use this to form $\\hat{y}_{t+2|t}$. Update the example code with the missing lines.\n",
    "\n",
    "To examine the predictions when the filter has converged, use the following code to plot the last 100 samples of $y_t$, $\\hat{y}_{t|t-1}$, and $\\hat{y}_{t+2|t}$.\n",
    "```python\n",
    "indV = range(N-102, N-1)\n",
    "plt.plot(indV, [y[indV], yhat1[indV], yhat2[indV]])\n",
    "plt.legend(['y_t', 'y_{t|t-1}', 'y_{t+2|t}'])\n",
    "plt.title('Data vs predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.xlim([indV[0], indV[-1]])\n",
    "```\n",
    "Notice that the plot stops at $N-2$. Why is that?\n",
    "\n",
    "Plot the estimated states and check that they converge properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef832a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code for task 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10759fb5",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "In Mozquizto, answer question 4.\n",
    "\n",
    "Again, it is important as you get your code to work properly as you will use this code in the project. Ask the teaching staff if you have problems!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fbf56",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Compute the sum of the squared prediction residual for the last 100 samples (why not all?). Can you improve the estimate, i.e., lower the sum of the squared prediction residual by tuning the choice of `Rw` and `Re`?\n",
    "\n",
    "Show the plot of $y_t$, $\\hat{y}_{t|t-1}$, and $\\hat{y}_{t+2|t}$, as well of the predicted states, to the teaching staff. Why is it that, in general, $\\hat{x}_{t+2|t} \\neq \\hat{x}_{t|t}$?\n",
    "\n",
    "**Be prepared to answer these questions when discussing with the examiner at the computer exercise!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37bfa8",
   "metadata": {},
   "source": [
    "It is worth noting that in case you are using the Kalman filter to predict an MA or an ARMA process, your `C` vector will contain earlier noise values, i.e., $e_t$, $e_{t-1}$, etc. These noise values are obviously not known, so one then use the corresponding one-step prediction errors in place of these, i.e., $\\epsilon_{t|t}$, $\\epsilon_{t-1|t-1}$, etc. These values are here stored in the variable `ehat`.\n",
    "\n",
    "*Important:* Note that when using the Kalman filter for prediction, you *should not* use the polynomial division techniques discussed in the earlier computer exercise, as presented in Chapter 6 in the course textbook. This will not yield the correct estimates! Instead, predictions needs to be made by updating the states as indicated in Chapter 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233e11b",
   "metadata": {},
   "source": [
    "## 2.4 Quality control of a process\n",
    "\n",
    "In the quality control division at a factory, one has found that the process which is to be followed shows a drift like\n",
    "$$\n",
    "x_t = x_{t-1} + e_t .\n",
    "$$\n",
    "However, it is not possible to measure the quality variable $x_t$ exactly, and one instead is limited to the observations\n",
    "$$\n",
    "y_t = x_t + bu_t + v_t ,\n",
    "$$\n",
    "where the processes $e_t$ and $v_t$ are two mutually uncorrelated sequences of white noise, with the variances $\\sigma_e^2$ and $\\sigma_v^2$. Furthermore, $b$ is a parameter. For simplicity, we assume that the external signal $u_t$ is known.\n",
    "\n",
    "Use the script written in the preparatory exercise for the computer exercise to simulate the process with the input signal $u_t$. Select $b=20$, $\\sigma_e^2 = 1$ and $\\sigma_v^2 = 4$, but feel free to change these at will. Now consider $x_t$ and $b$ to be unknown, and use the Kalman filter you prepared and implement a filter that estimates $b$. Plot your estimates of the hidden states together with the true values. Plot the one-step prediction $\\hat{y}_{t|t-1}$ as compared to the measured signal $y_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code for task 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d97f8",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "How should the state space vector be chosen? How would you choose an initial value of `Re` and `Rw`? How can then proceed to fine-tune the filter?\n",
    "\n",
    "**Be prepared to answer these questions when discussing with the examiner at the computer exercise!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec6e13",
   "metadata": {},
   "source": [
    "## 2.5 Recursive temperature modeling\n",
    "\n",
    "The file `svedala94.mat` contains temperature measurements from the Swedish city Svedala, taken every four hours throughout 1994.\n",
    "\n",
    "One potential model to describe the temperature with can be a SARIMA$(2,0,2)\\times(0,1,0)_6$ process, i.e., $A(z)\\nabla_6 y_t = C(z)e_t$, where the $A(z)$ and $C(z)$ polynomials are of order 2.\n",
    "\n",
    "### 1. Plot the temperature and differentiated data\n",
    "\n",
    "Plot the temperature, differentiate the process to form $\\nabla_6 y_t$ (use `signal.lfilter` and remember those initial samples) and plot the differentiated temperature. To obtain months on the x-axis, use\n",
    "```python\n",
    "T = pd.date_range(start='1994-01-01', end='1994-12-31', periods=len(svedala94))\n",
    "plt.plot(T, svedala94)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load svedala94 data\n",
    "mat_data = sio.loadmat('../data/svedala94.mat')\n",
    "y = mat_data['svedala94'].flatten()\n",
    "\n",
    "ydiff = ?\n",
    "\n",
    "# Create time vector\n",
    "T = pd.date_range(start='1994-01-01', end='1994-12-31', periods=len(ydiff))\n",
    "\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(T, y)\n",
    "plt.title('Original Temperature Data (Svedala 1994)')\n",
    "plt.ylabel('Temperature')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(T, ydiff)\n",
    "plt.title('Differentiated Temperature Data (âˆ‡6)')\n",
    "plt.ylabel('Temperature Difference')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaabe1e",
   "metadata": {},
   "source": [
    "### 2. Estimate model parameters for different periods\n",
    "\n",
    "Determine your own model for the first 540 samples. One potential model could be an ARMA(3,6), formed as\n",
    "$$\n",
    "\\nabla_6 ( 1 + a_1 z^{-1} + a_2 z^{-2} + a_3 z^{-3})y_t = (1 + c_6 z^{-6}) e_t\n",
    "$$\n",
    "Did you get a similar model? To allow comparisons, we will now use the above ARMA(3,6) model. Estimate the parameters for this model for a) the winter (say, January to March, i.e., samples 1 to 540), b) summer (say, June to August, i.e., samples 907 to 1458), and c) for the entire year. Compare the different estimated parameters. Do they seem to change? Does the model seem to work reasonably throughout the year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d554da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code for task 2.5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f48e3",
   "metadata": {},
   "source": [
    "### 3. One-step prediction using winter model\n",
    "\n",
    "Use the winter model to form a one-step prediction of the temperature for the validation data, here the last 400 samples, i.e., samples 1790 to 2190. To do so, add in the differentiated season in the model before computing the $G(z)$ polynomial to ensure that the prediction is formed in the correct domain. Apply the resulting filter to the *entire* signal. Then, cut out the part of the prediction that forms the validation data (this way you avoid any initialization problems). Plot the ACF of the resulting prediction residual for the validation data and compute its variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code for task 2.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f7e2a",
   "metadata": {},
   "source": [
    "### 4. Kalman filter estimation throughout the year\n",
    "\n",
    "Use the Kalman filter to estimate the parameters of the ARMA(3,6) model throughout the year. To do so requires some care. To begin with, do not remove the initial samples when forming $z_t = \\nabla_6 y_t = y_t - y_{t-6}$. Clearly, these initial samples will be corrupted, as always, but we will instead remove these later to simplify the alignment of the vectors. Then, form the Kalman filter predict $\\hat{z}_{t|t-1}$ using the ARMA structure above using the appropriate `C` vector. As\n",
    "$$\n",
    " \\hat{y}_{t|t-1}=  \\hat{z}_{t|t-1} + y_{t-6}\n",
    "$$\n",
    "you can reconstruct $\\hat{y}_{t|t-1}$ using:\n",
    "```python\n",
    "zt = C @ x_t1                # \\hat{z}_{t|t-1}\n",
    "yhat[t] = zt + y[t-6]        # \\hat{y}_{t|t-1}\n",
    "```\n",
    "Next, you can initiate the model at the beginning of the data set using the parameters you have found from the modeling data. To make the plots a bit nicer, we do this also for the states before the predictions:\n",
    "```python\n",
    "xt = np.zeros((p0+q0, N))\n",
    "for k in range(6):\n",
    "    xt[:, k] = np.concatenate([winterModel.A[1:], [winterModel.C[-1]]])\n",
    "```\n",
    "Here, the parameters `p0` and `q0` indicate the number of unknown coefficients in the $A(z)$ and $C(z)$-polynomials, respectively. As this choice of initial states should be fairly accurate, you trust your initial estimates to be reasonably good and can thus select a low initial $R_{1|0}^{x,x}$, for instance using\n",
    "```python\n",
    "Rx_t1 = 1e-5 * np.eye(p0+q0)\n",
    "Re    = 1e-5 * np.eye(p0+q0)\n",
    "Rw    = 2\n",
    "```\n",
    "where we have also selected rather low values for $R_w$ and $R_e$; try using some different values to get a feel for how these choices affect the resulting estimates and if you can improve the quality of the estimates. Note that you can (and maybe should?) have different parameter variances.\n",
    "\n",
    "Compare the resulting prediction with the result you got above when using the winter model as well as with the naive predictor. As you can see, the winter model is actually rather stable and actually works quite well even for the validation data, even without allowing the parameters to vary. Can you suggest any reasons why this might be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fa1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code for task 2.5.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aedf53",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Multi-step predictions\n",
    "\n",
    "Proceed to plot the 2-step and 3-step predictions of the temperature data. It is worth noting that the 3-step prediction will need to use the 2-step prediction. Compute the variance of the corresponding prediction residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54043e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your code for task 2.5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e02da",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "**Be prepared to show your parameter estimates and predictions when discussing with the examiner at the computer exercise!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56c253",
   "metadata": {},
   "source": [
    "## 2.6 (optional) Examine the project data\n",
    "\n",
    "Using the model for the input signal you developed in the second computer exercise, form a one-step prediction of this signal using a Kalman filter. Select the state covariances using the variance of the estimated prediction residual and the standard deviation of the parameter estimates you obtained in the second computer exercise. Initiate your parameters with the values you obtain in the second exercise.\n",
    "\n",
    "Start the filtering at the beginning of the entire data set, to avoid any initialization and convergence effects, and then extract the predictions for the validation data. Is the prediction residual white? Compute the variance of the prediction residual. Plot the estimated parameters. Are these similar to the ones you had with the fixed model? Are some parameters very small in comparison to their standard deviations? Are they significant? Can you remove some parameters without increasing the variance of the prediction residual more than marginally? Do you get better estimates if you fix some of the parameters so that these are not allowed to vary, instead using the parameter value you had from the second exercise?\n",
    "\n",
    "Form a $k$-step prediction of the input using the Kalman filter. Recall that you need to update the `C_t` vector at each step. How should you handle the future noise estimates? Examine the ACF of the prediction residual as well as its variance. Do you get a lower variance than you had for your fixed-parameter model?\n",
    "\n",
    "*Hint:* You will typically perform these task as part of your project, so the time you spend on this now will be time saved later on..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543f4f7",
   "metadata": {},
   "source": [
    "## 3. Kalman Filter Outline\n",
    "\n",
    "Below is an example of a Kalman filter implementation for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742dd37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Kalman filter\n",
    "\n",
    "# Simulate N samples of a process to test your code.\n",
    "y = ?                       # Simulated data          \n",
    "\n",
    "# Define the state space equations. \n",
    "A   = ?\n",
    "Re  = ?                     # State covariance matrix\n",
    "Rw  = ?                     # Observation variance\n",
    "\n",
    "# Set some initial values\n",
    "Rx_t1 = ? * np.eye(?)       # R_{1|0}^{x,x}\n",
    "h_et  = np.zeros(?)         # Estimated prediction error.\n",
    "xt    = np.zeros((?, ?))    # Estimated states. \n",
    "yhat1 = np.zeros(?)         # Estimated 1-step prediction.\n",
    "yhat2 = np.zeros(?)         # Estimated 2-step prediction.\n",
    "\n",
    "# Where should the loop start and stop?\n",
    "for t in range(?, ?):\n",
    "\n",
    "   # Update the predicted state \n",
    "    x_t1 = A @ xt[:, t-1]               # x_{t|t-1} \n",
    "    Ct = ?                              # C_{t|t-1}\n",
    "    \n",
    "    # Update the parameter estimates.\n",
    "    Ry = ?                              # R_{t|t-1}^{y,y}\n",
    "    Kt = ?                              # K_t\n",
    "    yhat = Ct @ x_t1                    # \\hat{y}_{t|t-1}.\n",
    "    h_et[t] = y[t] - yhat               # Prediction error,\n",
    "    xt[:, t] = x_t1 + Kt * h_et[t]      # x_{t|t}\n",
    "\n",
    "    # Update the covariance matrix estimates.\n",
    "    Rx_t  = ?                           # R^{x,x}_{t|t}\n",
    "    Rx_t1 = ?                           # R^{x,x}_{t+1|t} \n",
    "\n",
    "    # Form \\hat{y}_{t+1|t}.\n",
    "    Ct1 = ?                             # C_{t+1|t}\n",
    "    yhat1[t+1] = Ct1 @ xt[:, t]         # \\hat{y}_{t+1|t} \n",
    "\n",
    "    # Form \\hat{y}_{t+2|t}.\n",
    "    Ct2 = ?                             # C_{t+2|t}\n",
    "    yhat2[t+2] = Ct2 @ xt[:, t]         # \\hat{y}_{t+2|t}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
